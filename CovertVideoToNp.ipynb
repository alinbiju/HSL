{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ecbb12-2489-4649-935b-72a3e38e08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the path to your video files and the output directory\n",
    "video_folder = 'C:/Users/ALIN/OneDrive/Desktop/HSL/videoSamples/2. quiet'\n",
    "output_directory = 'C:/Users/ALIN/OneDrive/Desktop/HSL/MP_DATA/quiet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776b5fc9-dca6-4944-9f1d-18cdcff7890c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extraction completed.\n"
     ]
    }
   ],
   "source": [
    "# List of video file names (e.g., video1.mov, video2.mov, etc.)\n",
    "video_files = ['MVI_5180.MOV','MVI_5181.MOV','MVI_5182.MOV','MVI_5260.MOV','MVI_5261.MOV','MVI_5262.MOV','MVI_5338.MOV',\n",
    "               'MVI_5339.MOV','MVI_5340.MOV','MVI_9292.MOV','MVI_9293.MOV','MVI_9294.MOV','MVI_9371.MOV','MVI_9372.MOV',\n",
    "               'MVI_9373.MOV','MVI_9451.MOV','MVI_9452.MOV','MVI_9452.MOV','MVI_9453.MOV','MVI_9537.MOV','MVI_9538.MOV','MVI_9539.MOV']\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Function to extract frames from a video and save them as .np files\n",
    "def extract_frames(video_path, output_folder, video_name, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = frame_count // num_frames\n",
    "\n",
    "    # Create a subfolder for each video\n",
    "    video_output_folder = os.path.join(output_folder, video_name)\n",
    "    if not os.path.exists(video_output_folder):\n",
    "        os.makedirs(video_output_folder)\n",
    "\n",
    "    frame_number = 0\n",
    "    frame_index = 0\n",
    "\n",
    "    while frame_index < num_frames:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        if frame_number % frame_interval == 0:\n",
    "            frame_filename = os.path.join(video_output_folder, f'{frame_index}.npy')\n",
    "            # Convert the frame to a TensorFlow tensor\n",
    "            frame_tensor = tf.convert_to_tensor(frame, dtype=tf.uint8)\n",
    "            # Save the TensorFlow tensor as .npy\n",
    "            np.save(frame_filename, frame_tensor)\n",
    "            frame_index += 1\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Process each video file\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video_name = os.path.splitext(video_file)[0]\n",
    "    extract_frames(video_path, output_directory, video_name)\n",
    "\n",
    "print(\"Frames extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317bbfd-eab2-4ccd-b6f7-4fe517914f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "babab4cc-69d0-4a1a-8f55-a2433912de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extraction completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Define the input folder containing video filesdddd\n",
    "input_folder = 'C:/Users/ALIN/OneDrive/Desktop/HSL/videoSamples/2. quiet'\n",
    "\n",
    "# Define the output folder where frames will be saved\n",
    "output_directory = 'C:/Users/ALIN/OneDrive/Desktop/HSL/MP_DATA/quiet'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    # List video files in the input folder\n",
    "    video_files = [f for f in os.listdir(input_folder) if f.endswith('.mov')]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_file_path = os.path.join(input_folder, video_file)\n",
    "\n",
    "        # Initialize video capture from the video file\n",
    "        cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "        frame_num = 0  # Initialize frame number\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            print(results)\n",
    "\n",
    "            # Draw Landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "\n",
    "            if frame_num == 0:\n",
    "                cv2.putText(image, 'STARTING COLLECTION', (120, 200),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Collecting frames for Video', (15, 12),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.waitKey(2000)\n",
    "            else:\n",
    "                cv2.putText(image, 'Collecting frames for Video', (15, 12),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "            keypoints = extract_keypoints(results)\n",
    "            npy_path = os.path.join(output_directory, f'{video_file}_{frame_num}.npy')\n",
    "            np.save(npy_path, keypoints)\n",
    "\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            frame_num += 1\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Frames extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef91b6-46b0-4ae7-ab5e-1d6fed869453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
